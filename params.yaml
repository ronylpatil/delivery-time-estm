# parameters
base:
  project_name: delivery-time-estimation
  target: Time_taken(min)

load_dataset:
  bucket: delivery-time-estimate-data
  filename: train.csv
  raw_data: /data/raw

make_dataset:
  input_path: data/raw/train.csv
  holdout_split: 0.2
  unit_test_split: 0.1
  seed: 42
  train_test_path: /data/interim
  unit_test_path: /tests/data

feature_engineering:
  input_path__train: data/interim/train.csv
  input_path__test: data/interim/test.csv
  export_path: /data/processed
  labels_: src/features/labels.txt
  filename_train: processed_train
  filename_test: processed_test

mlflow:
  repo_owner: ronylpatil
  repo_name: delivery-time-estm

train_model:
  # {decision_tree: 'dt', random_forest: 'rf', gradient boost: 'gb', xgboost: 'xgb', all models: 'all'}
  model_to_train: lightgbm
  model_name: model_lgbm        # IMP PLEASE CHANGE NAME

  decision_tree:
    criterion: squared_error
    max_depth: 35
    min_samples_split: 40
    min_samples_leaf: 200
    max_features: sqrt
    max_leaf_nodes: 80

  random_forest:
    n_estimators: 100
    criterion: squared_error
    max_depth: 10
    min_samples_split: 40
    min_samples_leaf: 150
    max_features: 0.7
    max_leaf_nodes: 50
    oob_score: True
    max_samples: 9000

  gradient_boost:
    loss: squared_error
    learning_rate: 0.2
    n_estimators: 100
    subsample: 0.6
    min_samples_split: 50
    min_weight_fraction_leaf: 0.3 
    max_depth: 3
    max_features: 0.7
    max_leaf_nodes: 50
    n_iter_no_change: 13

  xgb:
    booster: gbtree # {gbtree, gblinear, dart}
    verbosity: 0 # {print message for debuging 0: None, 1: warning, 2: info, 3: debug}
    eta: 0.3 # {learning rate}
    gamma: 0 # {}
    max_depth: 6 # {}
    lambda: 1
    alpha: 0

tune_model:
  model_name: xgb_tunned
  n_trials: 100
